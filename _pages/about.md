---
layout: about
title: About
permalink: /
subtitle: Master student @Tsinghua University

profile:
  align: right
  image: prof_img.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p></p>
    <p></p>
    <p></p>

news: false # includes a list of news items
latest_posts: false # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

Hi, there ðŸ‘‹

I am a Master student at [Tsinghua Shenzhen International Graduate School (SIGS)](https://www.sigs.tsinghua.edu.cn/en/), [Tsinghua University](https://www.tsinghua.edu.cn/en/index.htm), advised by Prof. [Shu-tao Xia](https://www.sigs.tsinghua.edu.cn/xst_en/main.htm). I also work closely with Prof. [Tao Dai](https://scholar.google.com.hk/citations?user=MqJNdaAAAAAJ&hl=zh-CN&oi=ao) and Prof. [Yawei Li](https://yaweili.bitbucket.io/). Before that, I obtained my dual degree of B.Eng. & B.Ec. from [Nankai University](https://en.nankai.edu.cn/). 


My research interests focus on:

- **Generative Computer Vision**: trying to build a realistic digital world, such as image generation, image restoration, image super-resolution, etc.
- **Efficient Artificial Intelligence**: trying to allow AI available for everyone, such as parameter efficient fine-tuning, network quantization, sparsity, distillation, etc.


<div class="alert alert-info" style="max-width: 660px; color: #5445b4; background-color: #F0F8FF;">
<span style="color: #5445b4;">
<b>Looking for a PhD Position!</b> <br>
I am actively seeking a PhD position or an academic internship. If you are interested, feel free to contact me.ðŸ¤—.
</span>
</div>


### Contact

email: cshguo[at]gmail[dot]com

*(Last Update: 2025-06-27)*

### News
<div class="news">
  <div class="table-responsive" style="max-height: 16vw">
    <table class="table table-sm table-borderless">
      <tr>
        <th scope="row" style="width: 150px;">June 26, 2025</th>
        <td>
        Our <a href="https://github.com/csguoh/FastVAR" target="_blank"><b>FastVAR</b></a> has been accepted by ICCV25ðŸ¥³.
        </td>
      </tr> 
      <tr>
        <th scope="row" style="width: 150px;">June 03, 2025</th>
        <td>
        I start my summer internship at <a href="https://www.epfl.ch/en/" target="_blank"><b>EPFL</b></a> in Lausanne:D 
        </td>
      </tr> 
      <tr>
        <th scope="row" style="width: 150px;">May 02, 2025</th>
        <td>
        Our IntLoRA has been accepted by  <strong>ICML2025</strong>! Check our paper <a href="https://arxiv.org/abs/2410.21759" target="_blank"><b>here</b></a> :D
        </td>
      </tr> 
      <tr>
        <th scope="row" style="width: 150px;">Apr 29, 2025</th>
        <td>
        Two papers have been accepted by  <strong>IJCAI2025</strong>.
        </td>
      </tr> 
      <tr>
        <th scope="row" style="width: 150px;">Mar 28, 2025</th>
        <td>
        We release <a href="https://github.com/csguoh/FastVAR" target="_blank"><b>FastVAR</b></a>, a new cached token pruning method for <strong>2.7x faster</strong> Visual Auto-regressive Modeling.
        </td>
      </tr> 
      <tr>
        <th scope="row" style="width: 150px;">Feb 27, 2025</th>
        <td>
        Congrats! Our MambaIRv2 has been accepted by  <strong>CVPR2025</strong>!
        </td>
      </tr> 
      <tr>
        <th scope="row" style="width: 150px;">Feb 08, 2025</th>
        <td>
        We are organizing the CVPR25 Workshop <a href="https://www.cvlai.net/ntire/2025/" target="_blank"><b>NTIRE 2025 Challenge</b></a> on <a href="https://codalab.lisn.upsaclay.fr/competitions/21560" target="_blank"><b> Image Denosing</b></a>. 
        </td>
      </tr> 
      <tr>
        <th scope="row" style="width: 150px;">Feb 07, 2025</th>
        <td>
        We are organizing the CVPR25 Workshop <a href="https://www.cvlai.net/ntire/2025/" target="_blank"><b>NTIRE 2025 Challenge</b></a> on  <a href="https://codalab.lisn.upsaclay.fr/competitions/21620" target="_blank"><b>Efficient Super-Resolution</b></a>. 
        </td>
      </tr> 
      <tr>
        <th scope="row" style="width: 150px;">Dec 22, 2024</th>
        <td>
          Our work CALF, a LLM-based time series foundation models, has been accepted by <strong>AAAI2025</strong>!
        </td>
      </tr> 
      <tr>
        <th scope="row" style="width: 150px;">Nov 30, 2024</th>
        <td>
          Big News! <strong>MambaIRv2</strong> has been Arxived with huge performance leap! Check our paper <a href="http://arxiv.org/abs/2411.15269" target="_blank"><b>here</b></a>.
        </td>
      </tr> 
      <tr>
        <th scope="row" style="width: 150px;">Nov 15, 2024</th>
        <td>
         Congratulations! I have been honored as the <strong>Top Reviewer</strong> by <a href="https://neurips.cc/Conferences/2024/ProgramCommittee#top-reviewers" target="_blank">NeurIPS24 PCs</a>!
        </td>
      </tr> 
      <tr>
        <th scope="row" style="width: 150px;">Oct 15, 2024</th>
        <td>
          We release <strong>IntLoRA</strong>, which allows LoRA tuning on quantized models. Check our paper <a href="https://arxiv.org/pdf/2410.21759" target="_blank"><b>here</b></a> :D
        </td>
      </tr> 
      <tr>
        <th scope="row" style="width: 150px;">Sep 30, 2024</th>
        <td>
          Two first-author works, AdaptIR and ReFIR, have been accepted by <strong>NeurIPS2024</strong>!
        </td>
      </tr> 
      <tr>
        <th scope="row" style="width: 150px;">Jul 03, 2024</th>
        <td>
          Important! We have released the <a href="https://github.com/csguoh/Awesome-Mamba-in-Low-Level-Vision" target="_blank"><b>Awesome-Mamba-in-LLV</b></a>, collecting recent Mamba-based methods!
        </td>
      </tr> 
      <tr>
        <th scope="row" style="width: 150px;">Jul 01, 2024</th>
        <td>
          The first Mamba-based image restoration backbone, <strong>MambaIR</strong>, has been accepted by <strong>ECCV2024</strong>!
        </td>
      </tr> 
            <tr>
        <th scope="row" style="width: 150px;">Aug 04, 2023</th>
        <td>
          One knowledge distillation based OCR for real-world degraded scene was accepted by <strong>MM2023</strong>!
        </td>
      </tr> 
            <tr>
        <th scope="row" style="width: 150px;">Apr 15, 2023</th>
        <td>
         One text image super-resolution work has been accepted by <strong>IJCAI2023</strong>!
        </td>
      </tr> 
    </table>
  </div> 
</div>



